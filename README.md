# AI推敲 Chrome Extension (WebLLM版)

選択したテキストをブラウザ内で動作するLLMで推敲してくれるChrome拡張機能です。
**ローカルサーバー不要！完全にブラウザ内で動作します。**

## 特徴

- 🚀 **サーバー不要** - WebLLMを使用してブラウザ内でLLMが動作
- 🔒 **プライバシー保護** - テキストが外部に送信されない
- 💰 **無料** - APIキー不要、課金なし
- ⚡ **高速** - 一度モデルを読み込めば高速に動作

## 機能

- ブラウザ上で選択したテキストを右クリックメニューから「AI推敲」を選択
- WebLLM（Llama-3.2-1B）がテキストを改善
- 推敲結果に対して追加の指示や質問が可能
- チャット形式でインタラクティブに対話

## セットアップ

### 1. 拡張機能のビルド

```bash
# extensionディレクトリに移動
cd extension

# 依存関係をインストール
npm install

# ビルド
npm run build
```

### 2. Chrome拡張機能のインストール

1. Chrome の設定メニューから「その他のツール」→「拡張機能」を開く
2. 右上の「デベロッパーモード」をオンにする
3. 「パッケージ化されていない拡張機能を読み込む」をクリック
4. このプロジェクトの `extension/dist` フォルダを選択

## 使い方

1. ブラウザ上で推敲したいテキストを選択
2. 右クリックして「AI推敲」を選択
3. ポップアップウィンドウに結果が表示されます
   - **初回起動時はモデルのダウンロードに数分かかります**
4. 追加の指示や質問があれば、チャット欄に入力して送信

## 開発

### 開発モード

```bash
# ファイルの変更を監視して自動ビルド
cd extension
npm run dev
```

### ビルド

```bash
# 本番用ビルド
cd extension
npm run build
```

## プロジェクト構成

```
chrome-extension-local-claude/
├── extension/              # Chrome拡張
│   ├── src/               # ソースコード
│   │   ├── background.js  # Service Worker（WebLLM統合）
│   │   └── popup.js       # ポップアップUI
│   ├── dist/              # ビルド済みファイル（自動生成）
│   ├── manifest.json      # 拡張機能マニフェスト
│   ├── popup.html         # ポップアップHTML
│   ├── package.json       # npm設定
│   ├── webpack.config.js  # Webpack設定
│   └── icons/             # 拡張アイコン
└── README.md
```

## 技術スタック

- **Chrome Extension API** (Manifest V3)
- **WebLLM** - ブラウザ内でLLMを動作させるライブラリ
- **Llama-3.2-1B** - 軽量で高性能なLLMモデル
- **Webpack** - バンドラー

## システム要件

- Google Chrome（最新版推奨）
- 4GB以上のRAM（8GB推奨）
- 2GB以上の空きストレージ（モデルキャッシュ用）

## 注意事項

- 初回起動時はモデルのダウンロードに時間がかかります（約1GB）
- モデルはブラウザにキャッシュされるため、2回目以降は高速に起動します
- プライバシーを重視する場合やオフライン環境での使用に最適です

## トラブルシューティング

### モデルの読み込みが遅い
- 初回は時間がかかります。一度読み込めばキャッシュされます
- Chrome DevToolsのコンソールで進捗を確認できます

### メモリ不足エラー
- 他のタブを閉じてメモリを解放してください
- より小さいモデルへの変更も検討してください

### 拡張機能が動作しない
- Chrome DevToolsのコンソールでエラーを確認
- 拡張機能を再読み込み（chrome://extensions/）
- ビルドが正しく完了しているか確認

## カスタマイズ

### 異なるモデルの使用

`src/background.js`の以下の部分を編集して、別のモデルを使用できます：

```javascript
engine = await CreateMLCEngine(
  "Llama-3.2-1B-Instruct-q4f16_1", // ここを変更
  // 他のオプション例:
  // "TinyLlama-1.1B-Chat-v1.0-q4f16_1"
  // "Phi-3-mini-4k-instruct-q4f16_1"
);
```

利用可能なモデル: https://github.com/mlc-ai/web-llm#model-list

## 今後の改善案

- [ ] 複数のモデルから選択可能に
- [ ] 推敲スタイルの選択（丁寧、カジュアル、ビジネス等）
- [ ] 推敲履歴の保存機能
- [ ] ダークモード対応
- [ ] キーボードショートカット
- [ ] オフライン完全対応の強化

## ライセンス

MIT